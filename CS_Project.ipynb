{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS Project.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4oVfZQHL5iqj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "cellView": "form",
        "outputId": "fede432a-f853-4c73-b601-d246d12891a7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529075213512,
          "user_tz": 240,
          "elapsed": 2449,
          "user": {
            "displayName": "Zachary Shaver",
            "photoUrl": "//lh4.googleusercontent.com/-yspK4nfMBDw/AAAAAAAAAAI/AAAAAAAAAao/rk1kq96b-vQ/s50-c-k-no/photo.jpg",
            "userId": "100244708958275966637"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!pip install PyDictionary"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDictionary in /usr/local/lib/python3.6/dist-packages (1.5.2)\r\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from PyDictionary) (4.6.0)\r\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from PyDictionary) (2.18.4)\r\n",
            "Requirement already satisfied: goslate in /usr/local/lib/python3.6/dist-packages (from PyDictionary) (1.5.1)\r\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from PyDictionary) (6.7)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary) (2018.4.16)\r\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary) (2.6)\n",
            "Requirement already satisfied: futures in /usr/local/lib/python3.6/dist-packages (from goslate->PyDictionary) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_cuIdbiCoNJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Explanation\n",
        "First we need to install TensorFlow in the machine. Then `import` them.\n"
      ]
    },
    {
      "metadata": {
        "id": "T3r1F-MgzB9q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "form",
        "outputId": "3a263c6b-b072-44b9-b8b0-6ab54965bdb7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529075214757,
          "user_tz": 240,
          "elapsed": 1214,
          "user": {
            "displayName": "Zachary Shaver",
            "photoUrl": "//lh4.googleusercontent.com/-yspK4nfMBDw/AAAAAAAAAAI/AAAAAAAAAao/rk1kq96b-vQ/s50-c-k-no/photo.jpg",
            "userId": "100244708958275966637"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import requests\n",
        "from contextlib import closing\n",
        "import codecs\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras import utils\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import sklearn.datasets as skds\n",
        "from pathlib import Path\n",
        "from PyDictionary import PyDictionary\n",
        "pydict = PyDictionary()\n",
        "import urllib.request as urllib\n",
        "\n",
        "# Reproducability :D \n",
        "np.random.seed(7)\n",
        "\n",
        "randomTextURL = 'https://raw.githubusercontent.com/carykh/neuralNetworkLanguageDetection/master/data/output0.txt'\n",
        "keyMashTextURL = 'https://raw.githubusercontent.com/carykh/neuralNetworkLanguageDetection/master/data/output1.txt'\n",
        "#bigNotGibberishURL = 'https://raw.githubusercontent.com/rrenaud/Gibberish-Detector/master/big.txt'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mo9LKK6p-BLd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then download training data for the neural network and format it in a way that is readable by the network."
      ]
    },
    {
      "metadata": {
        "id": "--SXcmosrgNJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "data_words, data_labels = [], []\n",
        "\n",
        "with requests.get(randomTextURL) as randomText:\n",
        "  for row in randomText.text.split('\\n'):\n",
        "    if row is not []:\n",
        "      row = row.split(',')\n",
        "      data_words.append(row[0])\n",
        "      data_labels.append('Random Text')\n",
        "\n",
        "with requests.get(keyMashTextURL) as keyMash:\n",
        "  for row in keyMash.text.split('\\n'):\n",
        "    if row is not []:\n",
        "      row = row.split(',')\n",
        "      data_words.append(row[0])\n",
        "      data_labels.append('Keyboard Mash')\n",
        "  \n",
        "#for word in bigNotGibberish:\n",
        "#  pass # something\n",
        "  \n",
        "# lets take 80% data as training and remaining 20% for test.\n",
        "train_size = int(len(data_words) * .8)\n",
        " \n",
        "train_words = data_words[:]#train_size]\n",
        "train_labels = data_labels[:]#train_size]\n",
        "\n",
        "test_words = data_words[train_size:]\n",
        "test_labels = data_labels[train_size:]\n",
        "  \n",
        "# 2 different types\n",
        "num_labels = 2\n",
        "vocab_size = 15000\n",
        "batch_size = 100\n",
        " \n",
        "# define Tokenizer with Vocab Size\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(train_words)\n",
        " \n",
        "x_train = tokenizer.texts_to_matrix(train_words, mode='tfidf')\n",
        "x_test = tokenizer.texts_to_matrix(test_words, mode='tfidf')\n",
        " \n",
        "encoder = LabelBinarizer()\n",
        "encoder.fit(train_labels)\n",
        "y_train = encoder.transform(train_labels)\n",
        "y_test = encoder.transform(test_labels)\n",
        "\n",
        "y_train = utils.to_categorical(y_train, num_classes=num_labels)\n",
        "y_test = utils.to_categorical(y_test, num_classes=num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1xLtm4x_sDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then make and train the neural network"
      ]
    },
    {
      "metadata": {
        "id": "j62FKzP9zcjI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "cellView": "form",
        "outputId": "ca0acbfa-69f3-454f-f49c-7c498ef671d0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529076098902,
          "user_tz": 240,
          "elapsed": 27041,
          "user": {
            "displayName": "Zachary Shaver",
            "photoUrl": "//lh4.googleusercontent.com/-yspK4nfMBDw/AAAAAAAAAAI/AAAAAAAAAao/rk1kq96b-vQ/s50-c-k-no/photo.jpg",
            "userId": "100244708958275966637"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=[vocab_size]))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "model.summary()\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                      epochs=5,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 512)               7680512   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 7,944,194\n",
            "Trainable params: 7,944,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 20655 samples, validate on 2295 samples\n",
            "Epoch 1/5\n",
            "20655/20655 [==============================] - 6s 269us/step - loss: 0.5441 - acc: 0.7618 - val_loss: 0.1841 - val_acc: 0.8797\n",
            "Epoch 2/5\n",
            " 7200/20655 [=========>....................] - ETA: 3s - loss: 0.1384 - acc: 0.9475"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20655/20655 [==============================] - 5s 250us/step - loss: 0.1374 - acc: 0.9470 - val_loss: 0.1974 - val_acc: 0.9294\n",
            "Epoch 3/5\n",
            "20655/20655 [==============================] - 5s 251us/step - loss: 0.0820 - acc: 0.9513 - val_loss: 0.2249 - val_acc: 0.9011\n",
            "Epoch 4/5\n",
            "20655/20655 [==============================] - 5s 250us/step - loss: 0.0733 - acc: 0.9551 - val_loss: 0.2205 - val_acc: 0.9098\n",
            "Epoch 5/5\n",
            "20655/20655 [==============================] - 5s 250us/step - loss: 0.0720 - acc: 0.9552 - val_loss: 0.2353 - val_acc: 0.9176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GrdVaWXVuRaD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "cellView": "form",
        "outputId": "c1abdc79-6ac8-4d5f-ba5b-601f727eae5d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529076143145,
          "user_tz": 240,
          "elapsed": 2310,
          "user": {
            "displayName": "Zachary Shaver",
            "photoUrl": "//lh4.googleusercontent.com/-yspK4nfMBDw/AAAAAAAAAAI/AAAAAAAAAao/rk1kq96b-vQ/s50-c-k-no/photo.jpg",
            "userId": "100244708958275966637"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "inp = input('Enter a term to test: > ')\n",
        "\n",
        "output = model.predict(tokenizer.texts_to_matrix([inp], mode='tfidf'), batch_size=batch_size)\n",
        "print(output)\n",
        "if output[0][0] > 0.75: \n",
        "  print('Keyboard Mashing')\n",
        "elif output[0][1] > 0.75:\n",
        "  print('Random Text')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a term to test: > ZQOEIEHZUUUKJUO\n",
            "[[1.9290135e-04 9.9980718e-01]]\n",
            "Random Text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "43p4UAAQ4yn2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Given a single, one-line string, determine if it contains an english word or\n",
        "# not. If it does, determine whether this random text was produced via keyboard\n",
        "# mashing or if it was randomly generated by a computer. Keyboard mashing likely\n",
        "# contains letters around a certain key: if one key is pressed, as well as 6\n",
        "# surrounding keys (at least 4), and this pattern appears for 75% of all of the\n",
        "# random text, then it was probably mashed.\n",
        "\n",
        "gibberish = True\n",
        "gibberish_count = 0\n",
        "total_gib_count = 0\n",
        "\n",
        "def determine_gibberish(line):\n",
        "  global gibberish\n",
        "  global gibberish_count\n",
        "  global total_gib_count\n",
        "  words = line.split()\n",
        "  print(pydict.meaning(line))\n",
        "  if pydict.meaning(line) is None:\n",
        "    gibberish_count+=1\n",
        "    total_gib_count+=1\n",
        "  else:\n",
        "    total_gib_count+=1\n",
        "  #for word in words:\n",
        "    #print(\"word: \" + word)\n",
        "    \n",
        "      \n",
        "  print(\"total count: \" + str(total_gib_count))\n",
        "  print(\"gib count: \" + str(gibberish_count))\n",
        "  if gibberish_count / total_gib_count < 0.25:\n",
        "    gibberish = False\n",
        "    \n",
        "  return gibberish\n",
        "\n",
        "def percent_gibberish(line):\n",
        "  global gibberish\n",
        "  global gibberish_count\n",
        "  global total_gib_count\n",
        "  words = line.split()\n",
        "  print(pydict.meaning(line))\n",
        "  if pydict.meaning(line) is None:\n",
        "    gibberish_count+=1\n",
        "    total_gib_count+=1\n",
        "  else:\n",
        "    total_gib_count+=1\n",
        "  #for word in words:\n",
        "    #print(\"word: \" + word)\n",
        "    \n",
        "      \n",
        "  print(\"total count: \" + str(total_gib_count))\n",
        "  print(\"gib count: \" + str(gibberish_count))\n",
        "  print (gibberish_count / total_gib_count)\n",
        "  return gibberish_count / total_gib_count\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yx0uXBwy_wr0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def determine_mashing(line):\n",
        "  # assumes line is gibberish\n",
        "  # key set only includes the alphabet, not the other keys on the keyboard because i'm lazy\n",
        "  common_keys = {\"Q\":[\"W\",\"A\",\"S\"],\"W\":[\"Q\",\"A\",\"S\",\"D\",\"E\"], \"E\":[\"W\",\"S\",\"D\",\"F\",\"R\"], \"R\":[\"E\",\"D\",\"F\",\"G\",\"T\"],\"T\":[\"R\",\"F\",\"G\",\"H\",\"Y\"],\n",
        "                \"Y\":[\"T\",\"G\",\"H\",\"J\",\"Y\"], \"U\":[\"Y\",\"H\",\"J\",\"I\",\"K\"], \"I\":[\"U\",\"J\",\"K\",\"L\",\"O\"], \"O\":[\"I\",\"K\",\"L\",\"P\"],\n",
        "                \"A\":[\"Q\",\"W\",\"S\",\"Z\"],\"S\":[\"Q\",\"W\",\"E\",\"D\",\"X\",\"Z\",\"A\"],\"D\":[\"W\",\"E\",\"R\",\"F\",\"C\",\"X\",\"S\"],\"F\":[\"D\",\"E\",\"R\",\"T\",\"G\",\"V\",\"C\"],\n",
        "                \"G\":[\"R\",\"T\",\"Y\",\"H\",\"B\",\"V\",\"F\"],\"H\":[\"T\",\"Y\",\"U\",\"J\",\"N\",\"B\",\"G\"],\"J\":[\"Y\",\"U\",\"I\",\"K\",\"M\",\"N\",\"H\"],\n",
        "                \"K\":[\"U\",\"I\",\"O\",\"L\",\"M\",\"J\"],\"L\":[\"I\",\"O\",\"P\",\"K\",\"M\"],\"Z\":[\"A\",\"S\",\"X\"],\"X\":[\"Z\",\"S\",\"D\",\"C\"],\"C\":[\"X\",\"D\",\"F\",\"V\"],\n",
        "                \"V\":[\"C\",\"F\",\"G\",\"B\"],\"B\":[\"V\",\"G\",\"H\",\"N\"],\"N\":[\"B\",\"H\",\"J\",\"M\"],\"M\":[\"N\",\"J\",\"K\",\"L\",\",\"]}\n",
        "  \n",
        "  mashing = False\n",
        "  mash_count = 0\n",
        "  total_count = 1\n",
        "  words = str(line.split())\n",
        "  letters = list(words)\n",
        "\n",
        "  for word in words: # I think this might not work because it doesn't move on to another word until it checked the same thing a bunch of times\n",
        "    if words.index(word) + 3 is not None and words.index(word) - 3 is not None:\n",
        "      for letter in letters:   \n",
        "        if ((letters.index(letter) in common_keys and (letters[letters.index(letter) + 1] in common_keys\n",
        "                                                    and letters[letters.index(letter) + 2] in common_keys\n",
        "                                                    and letters[letters.index(letter) + 3] in common_keys)) \n",
        "        or (letters.index(letter) in common_keys and (letters[letters.index(letter) - 1] in common_keys\n",
        "                                                     and letters[letters.index(letter) - 2] in common_keys\n",
        "                                                     and letters[letters.index(letter) - 3] in common_keys))):\n",
        "          mash_count+=1\n",
        "          total_count+=1\n",
        "    elif words.index(word) + 2 is not None and words.index(word) - 2 is not None:\n",
        "      for letter in letters:\n",
        "        if ((letters.index(letter) in common_keys and (letters[letters.index(letter) + 1] in common_keys\n",
        "                                                     and letters.index(letter) + 2 in common_keys))\n",
        "        or (letters.index(letter) in common_keys and (letters.index(letter) - 1 in common_keys\n",
        "                                                     and letters.index(letter) - 2 in common_keys))):\n",
        "          mash_count+=1\n",
        "          total_count+=1\n",
        "    elif words.index(word) + 1 is not None and words.index(word) - 1 is not None:\n",
        "      for letter in letters:\n",
        "        if ((letters.index(letter) in common_keys and (letters.index(letter) + 1 in common_keys))\n",
        "        or (letters.index(letter) in common_keys and (letters.index(letter) - 1 in common_keys))):\n",
        "          mash_count+=1\n",
        "          total_count+=1\n",
        "    else:\n",
        "      total_count+=1\n",
        "      \n",
        "  if (mash_count/total_count > 0.75):\n",
        "    mashing = True\n",
        "    \n",
        "  return mashing\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aJlm0NfyyUig",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "78201238-650c-4d35-bfff-b0d757bae2a9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529076232398,
          "user_tz": 240,
          "elapsed": 9274,
          "user": {
            "displayName": "Matthew Stanciu",
            "photoUrl": "//lh6.googleusercontent.com/-5w34I6HOtTA/AAAAAAAAAAI/AAAAAAAAAXM/6tt4xJRRcCU/s50-c-k-no/photo.jpg",
            "userId": "105736452470826651375"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Prompt the user for input for a file, examine the file line by line, and determine\n",
        "# 1) whether or not it is gibberish, as well as the percent gibberish,\n",
        "# and 2) if it is gibberish, the percent mashed\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  gib_count = 0\n",
        "  total_everything_count = 0\n",
        "  mashing_count = 0\n",
        "  total_mashing_count = 0\n",
        "  \n",
        "  f = input(\"Enter the full link to the file you wish to examine: \")\n",
        "  data = urllib.urlopen(f)\n",
        "  raw_data = data.read().decode('utf-8')\n",
        "  spl = raw_data.split()\n",
        "  \n",
        "  for word in spl:\n",
        "    if determine_gibberish(word):\n",
        "        gib_count+=1\n",
        "        total_everything_count+=1\n",
        "    else:\n",
        "      total_everything_count+=1\n",
        "\n",
        "    if determine_mashing(word):\n",
        "      mashing_count+=1\n",
        "      total_mashing_count+=1\n",
        "    else:\n",
        "      total_mashing_count+=1\n",
        "        \n",
        "  calculated_gibberish = gib_count / total_everything_count\n",
        "  calculated_mashing = (mashing_count / total_mashing_count)*100\n",
        "  print(\"calculated gib: \" + str(calculated_gibberish))\n",
        "  print(\"total everything: \" + str(total_everything_count))\n",
        "  print(\"Your file is \" + str(calculated_mashing) + \"% gibberish\")\n",
        "    \n",
        "  if calculated_gibberish >= 0.75 and calculated_mashing >= 0.75:\n",
        "    print(\"Your file is determined to be gibberish and the result of keyboard mashing\")\n",
        "  elif calculated_gibberish >= 0.75 and calculated_mashing < 0.75:\n",
        "    print(\"Your file is determined to be gibberish and the result of some other form of random generation -- not keyboard mashing\")\n",
        "  else:\n",
        "    print(\"Your file is determined to not be gibberish\")\n",
        "  if percent_gibberish(raw_data) >= 0.75:\n",
        "    print(\"Your file is gibberish\")\n",
        "  else:\n",
        "    print(\"Your file is not gibberish\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the full link to the file you wish to examine: https://raw.githubusercontent.com/theblindbandet/Random-Text/master/notgibberish.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 193 of the file /usr/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
            "\n",
            " BeautifulSoup(YOUR_MARKUP})\n",
            "\n",
            "to this:\n",
            "\n",
            " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
            "\n",
            "  markup_type=markup_type))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Noun': ['an expression of greeting']}\n",
            "total count: 20\n",
            "gib count: 15\n",
            "{'Noun': ['an expression of greeting']}\n",
            "total count: 21\n",
            "gib count: 15\n",
            "Error: The Following Error occured: list index out of range\n",
            "None\n",
            "Error: The Following Error occured: list index out of range\n",
            "total count: 22\n",
            "gib count: 16\n",
            "{'Noun': ['a nonmetallic element belonging to the halogens; used especially in medicine and photography and in dyes; occurs naturally only in combination in small quantities (as in sea water or rocks', 'the smallest whole number or a numeral representing this number', 'the 9th letter of the Roman alphabet'], 'Verb': ['have the quality of being; (copula, used with an adjective or a predicate noun', 'be identical to; be someone or something', 'occupy a certain position or area; be somewhere', 'have an existence, be extant', 'happen, occur, take place', 'be identical or equivalent to', 'form or compose', 'work in a specific place, with a specific subject, or in a specific function', 'represent, as of a character on stage', 'spend or use time', 'have life, be alive', 'to remain unmolested, undisturbed, or uninterrupted -- used only in infinitive form', 'be priced at']}\n",
            "total count: 23\n",
            "gib count: 16\n",
            "Error: The Following Error occured: list index out of range\n",
            "None\n",
            "Error: The Following Error occured: list index out of range\n",
            "total count: 24\n",
            "gib count: 17\n",
            "Error: The Following Error occured: list index out of range\n",
            "None\n",
            "Error: The Following Error occured: list index out of range\n",
            "total count: 25\n",
            "gib count: 18\n",
            "{'Noun': ['(New Testament', 'one of the Gospels in the New Testament; includes the Sermon on the Mount']}\n",
            "total count: 26\n",
            "gib count: 18\n",
            "calculated gib: 1.0\n",
            "total everything: 7\n",
            "Your file is 0.0% gibberish\n",
            "Your file is determined to be gibberish and the result of some other form of random generation -- not keyboard mashing\n",
            "Error: A Term must be only a single word\n",
            "None\n",
            "Error: A Term must be only a single word\n",
            "total count: 27\n",
            "gib count: 19\n",
            "0.7037037037037037\n",
            "Your file is not gibberish\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}